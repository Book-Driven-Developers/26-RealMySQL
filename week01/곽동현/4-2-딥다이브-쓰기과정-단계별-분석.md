# 4.2 딥다이브: UPDATE 쿼리의 쓰기과정 단계별 분석

> **딥다이브 주제**: InnoDB에서 UPDATE 쿼리 한 줄이 실행될 때, 내부적으로 어떤 단계를 거쳐 데이터가 변경되고 디스크에 기록되는지 전체 여정을 추적한다. 어댑티브 해시 인덱스, 잠금, 언두 로그, 리두 로그, 체인지 버퍼, Double Write Buffer까지 모든 구성요소가 어떻게 협력하는지 분석한다.

---

## 🎯 분석 대상 쿼리

```sql
UPDATE member SET m_area = '경기' WHERE m_id = 12;
```

이 한 줄이 실행되면 InnoDB 내부에서 벌어지는 일을 **시간순**으로 따라간다.

---

## Phase 0: 쿼리 파싱 & 실행 계획 (MySQL 서버 엔진 레벨)

```
[0-1] MySQL 서버의 파서가 SQL 구문 분석
    "UPDATE member SET m_area='경기' WHERE m_id=12"
    → 문법 오류 없는지 확인

[0-2] 옵티마이저가 실행 계획 결정
    → m_id는 PK이므로 → "프라이머리 키 클러스터링 인덱스로 바로 접근"
    → B-Tree 탐색: 루트 → 브랜치 → 리프 노드

[0-3] 스토리지 엔진(InnoDB)에 "m_id=12 레코드를 찾아서 수정해줘" 요청
```

여기까지는 **InnoDB 밖**, MySQL 서버 엔진 레벨의 일이다.

---

## Phase 1: 대상 페이지를 버퍼 풀에 확보

```
[1-1] InnoDB 버퍼 풀에서 m_id=12가 포함된 페이지 검색
    ┌─────────────────────────────────────────┐
    │  어댑티브 해시 인덱스 확인               │
    │  → 해시 테이블에 m_id=12 있나?           │
    │    ├─ YES → 버퍼 풀 페이지 주소 즉시 획득 │  ← O(1), 나노초
    │    └─ NO  → B-Tree 인덱스 탐색으로 전환   │  ← O(logN)
    └─────────────────────────────────────────┘

[1-2] B-Tree 탐색 (어댑티브 해시에 없었을 경우)
    PK 인덱스의 루트 페이지 → 브랜치 페이지 → 리프 페이지
    각 페이지마다:
      ├─ 버퍼 풀에 있으면 → 메모리에서 바로 읽기
      └─ 버퍼 풀에 없으면 → 디스크에서 읽어서 버퍼 풀에 로드
                            (프리 리스트에서 빈 페이지 할당)
                            (프리 리스트도 없으면 → LRU에서 가장 오래된 페이지 제거)

[1-3] 최종적으로 m_id=12가 담긴 "데이터 페이지"를 버퍼 풀에 확보
```

여기서 중요한 점: **리프 페이지 하나가 16KB**이다. m_id=12 레코드만 읽는 게 아니라, 그 레코드가 포함된 **16KB 페이지 전체**를 메모리에 올린다. 같은 페이지에 m_id=11, 13 등도 함께 들어있을 수 있다.

---

## Phase 2: 잠금 획득

```
[2-1] 레코드 잠금 (Row Lock)
    ┌──────────────────────────────────────────┐
    │  m_id=12 레코드에 대해 X-Lock(배타 잠금) 획득 │
    │                                            │
    │  ├─ 다른 트랜잭션이 이 레코드를 잠그고 있나?  │
    │  │   ├─ NO  → 즉시 잠금 획득                │
    │  │   └─ YES → Wait-for List에 등록, 대기     │
    │  │           (innodb_lock_wait_timeout까지)  │
    │  │           (데드락 감지 스레드가 주기적 체크) │
    │  └──────────────────────────────────────────┘
    │
    │  X-Lock을 획득하면:                          │
    │  - 다른 트랜잭션의 UPDATE/DELETE → 대기       │
    │  - 다른 트랜잭션의 SELECT → MVCC로 잠금 없이 읽기 가능 │
    └──────────────────────────────────────────────┘
```

**이 단계가 중요한 이유**: 잠금을 못 얻으면 여기서 멈춘다. 흔히 말하는 "쿼리가 느리다"의 원인 중 하나가 이 잠금 대기이다.

---

## Phase 3: 언두 로그 기록

```
[3-1] 언두 로그에 "변경 전 데이터" 백업
    ┌─────────────────────────────────┐
    │  언두 로그 (언두 테이블스페이스)    │
    │                                 │
    │  트랜잭션 ID: TRX_100           │
    │  ┌───────────────────────┐      │
    │  │ 테이블: member          │      │
    │  │ PK: m_id=12            │      │
    │  │ 이전 값: m_area='서울'   │      │
    │  │ 롤백 포인터: 이전 버전    │  ← MVCC 버전 체인 연결
    │  └───────────────────────┘      │
    └─────────────────────────────────┘

[3-2] 이 언두 레코드의 용도 (2가지)
    ① ROLLBACK 시 → 이 값으로 복원
    ② 다른 트랜잭션이 READ_COMMITTED/REPEATABLE_READ로 조회 시
       → 아직 커밋 안 됐으므로, 이 언두 로그의 '서울' 값을 반환
```

---

## Phase 4: 버퍼 풀의 페이지 수정

```
[4-1] 버퍼 풀에서 해당 페이지의 데이터를 직접 수정
    ┌─────────────────────────────────────┐
    │  InnoDB 버퍼 풀                      │
    │  ┌─────────────────────────────┐    │
    │  │ 페이지 #4872                 │    │
    │  │ ┌─────────────────────────┐ │    │
    │  │ │ m_id=11 | m_area=부산   │ │    │
    │  │ │ m_id=12 | m_area=경기 ← │ │ 수정!  (이전: 서울)
    │  │ │ m_id=13 | m_area=대구   │ │    │
    │  │ └─────────────────────────┘ │    │
    │  │ 상태: [DIRTY]               │    │
    │  │ LSN: 100234 (수정 시점 기록)  │    │
    │  └─────────────────────────────┘    │
    └─────────────────────────────────────┘

[4-2] 더티 페이지로 표시 → 플러시 리스트에 등록
    ┌───────────────────────────────────┐
    │  플러시 리스트 (변경 시점순 정렬)    │
    │                                   │
    │  ... → 페이지#2301(LSN:100210)    │
    │      → 페이지#4872(LSN:100234) ← NEW!
    │                                   │
    │  (이 리스트를 보고 백그라운드 스레드가 │
    │   오래된 것부터 디스크에 기록한다)    │
    └───────────────────────────────────┘
```

**LSN(Log Sequence Number)**이 여기서 등장한다. 이 숫자가 리두 로그와 버퍼 풀을 연결하는 핵심 고리이다.

---

## Phase 5: 리두 로그 버퍼에 기록

```
[5-1] 리두 로그 버퍼 (메모리)에 변경 내역 기록
    ┌───────────────────────────────────────┐
    │  리두 로그 버퍼 (innodb_log_buffer_size) │
    │                                        │
    │  LSN:100234                            │
    │  ┌──────────────────────────────┐      │
    │  │ Type: UPDATE                  │      │
    │  │ Space: member 테이블           │      │
    │  │ Page: #4872                   │      │
    │  │ Offset: 120                   │      │
    │  │ 변경 내용: '서울' → '경기'      │      │
    │  │ 크기: 약 수십 바이트            │  ← 16KB 페이지 전체가 아님!
    │  └──────────────────────────────┘      │
    └───────────────────────────────────────┘
```

**핵심 차이**:
- 데이터 파일 쓰기: 16KB 페이지 전체
- 리두 로그 쓰기: "뭘 바꿨다"는 변경 내역만 → 수십~수백 바이트

---

## Phase 6: 세컨더리 인덱스 업데이트 (있는 경우)

만약 `m_area` 컬럼에 인덱스가 걸려있다면, **여기서 체인지 버퍼가 등장한다.**

```
[6-1] m_area에 세컨더리 인덱스가 있는 경우

    세컨더리 인덱스 페이지가 버퍼 풀에 있나?
    ├─ YES → 버퍼 풀에서 바로 인덱스 수정 (빠름)
    │        인덱스에서 '서울' → '경기'로 변경
    │
    └─ NO  → 체인지 버퍼에 "나중에 이 인덱스 수정해줘" 등록
             ┌─────────────────────────────────┐
             │  체인지 버퍼                      │
             │  "m_area 인덱스에서              │
             │   '서울' 삭제, '경기' 추가해줘"   │
             │                                 │
             │  → 나중에 해당 인덱스 페이지가    │
             │    버퍼 풀에 올라올 때 머지        │
             │    (체인지 버퍼 머지 스레드 담당)   │
             └─────────────────────────────────┘

    ⚠️ 단, 유니크 인덱스라면?
    → 체인지 버퍼 사용 불가!
    → 중복 체크를 위해 반드시 디스크에서 인덱스 페이지를 읽어야 함
    → 이것이 유니크 인덱스가 일반 인덱스보다 쓰기 성능이 떨어지는 이유
```

---

## Phase 7: 클라이언트에 응답

```
[7-1] 클라이언트에 "UPDATE 완료" 응답

    이 시점의 상태:
    ┌───────────────────────────────────────────┐
    │  메모리에 있는 것들:                        │
    │  ✅ 버퍼 풀: 수정된 데이터 (더티 페이지)     │
    │  ✅ 리두 로그 버퍼: 변경 내역               │
    │  ✅ 언두 로그: 이전 데이터 백업              │
    │                                           │
    │  디스크에 있는 것들:                        │
    │  ❌ 데이터 파일 (member.ibd): 아직 '서울'   │
    │  ❌ 리두 로그 파일: 아직 기록 안 됨 (설정에 따라) │
    └───────────────────────────────────────────┘
```

**아직 COMMIT 전이다.** 여기까지는 UPDATE문 실행만 완료된 상태이다.

---

## Phase 8: COMMIT 시점 — 여기가 진짜 핵심

```
[8-1] COMMIT 명령 실행

    innodb_flush_log_at_trx_commit 설정에 따라:

    ┌─── 설정값 = 1 (기본, 권장) ────────────────────┐
    │                                               │
    │  리두 로그 버퍼                                 │
    │       │                                       │
    │       ↓ write (메모리 → OS 버퍼)               │
    │                                               │
    │  OS 페이지 캐시                                │
    │       │                                       │
    │       ↓ fsync (OS 버퍼 → 디스크) ← 디스크 I/O! │
    │                                               │
    │  리두 로그 파일 (ib_logfile0, ib_logfile1)     │
    │                                               │
    │  fsync 완료 후에야 → "COMMIT 성공" 응답        │
    └───────────────────────────────────────────────┘

    이 시점의 보장:
    ✅ 리두 로그가 디스크에 확실히 기록됨
    ✅ 서버가 죽어도 이 트랜잭션은 복구 가능
    ❌ 하지만 데이터 파일(member.ibd)은 아직 갱신 안 됨!
```

**COMMIT 시점의 디스크 I/O는 딱 하나**: 리두 로그의 fsync뿐이다. 데이터 파일은 건드리지 않는다!

---

## Phase 9: 백그라운드 — 더티 페이지의 디스크 기록

COMMIT 이후, 사용자는 이미 떠났다. 이제 백그라운드에서 일어나는 일이다.

```
[9-1] Page Cleaner 스레드가 주기적으로 동작
    (innodb_page_cleaners = 8, 기본 8개 스레드)

    트리거 조건:
    ├─ 더티 페이지 비율 > innodb_max_dirty_pages_pct_lwm (10%)
    ├─ LRU 리스트에서 빈 공간이 필요할 때
    ├─ 리두 로그 공간이 부족할 때 (체크포인트 필요)
    └─ 어댑티브 플러싱 알고리즘 판단

[9-2] Double Write Buffer를 통한 안전한 쓰기

    왜 직접 데이터 파일에 안 쓰고 Double Write를 거치는가?

    16KB 페이지를 디스크에 쓰는 도중에 서버가 죽으면:
    ┌──────────────────┐
    │  디스크의 페이지    │
    │  앞 8KB: 새 데이터 │ ← 쓰기 완료
    │  뒤 8KB: 옛 데이터 │ ← 아직 안 씀
    └──────────────────┘
    → "Partial Page (Torn Page)" 발생!
    → 리두 로그로도 복구 불가능!
      (리두 로그는 "변경 내역"이지, 페이지 전체가 아님)
      (깨진 페이지에 변경 내역을 적용하면 → 더 깨짐)

    Double Write의 동작:

    Step A: 더티 페이지들을 모아서 Double Write 버퍼에 순차 쓰기
    ┌───────────────────────────────────────┐
    │  Double Write 버퍼 (시스템 테이블스페이스) │
    │  [페이지#4872][페이지#2301][페이지#887]  │
    │  ← 순차 쓰기 (빠름)                     │
    │  ← 여기서 죽어도 원본 데이터 파일은 무사   │
    └───────────────────────────────────────┘

    Step B: 이제 실제 데이터 파일의 각 위치에 랜덤 쓰기
    ┌────────────────────────────────┐
    │  member.ibd                    │
    │  ...                           │
    │  [페이지#4872] ← 새 데이터 쓰기  │  (랜덤 I/O)
    │  ...                           │
    └────────────────────────────────┘

    만약 Step B 도중에 서버가 죽으면?
    → 재시작 시 Double Write 버퍼와 데이터 파일을 비교
    → 불일치 발견 → Double Write 버퍼의 정상 페이지로 복원
    → 그 후 리두 로그를 적용하여 완전 복구
```

---

## 전체 흐름 한눈에 보기

```
클라이언트: UPDATE ... WHERE m_id=12
      │
      ↓
[Phase 0] 파서/옵티마이저 (MySQL 서버 엔진)
      │
      ↓
[Phase 1] 대상 페이지를 버퍼 풀에 확보
      │     (어댑티브 해시 → B-Tree 탐색 → 디스크 읽기)
      │
      ↓
[Phase 2] X-Lock 획득 (레코드 잠금)
      │
      ↓
[Phase 3] 언두 로그에 이전 값 백업 (MVCC + 롤백용)
      │
      ↓
[Phase 4] 버퍼 풀 페이지 수정 + 더티 표시 + 플러시 리스트 등록
      │
      ↓
[Phase 5] 리두 로그 버퍼에 변경 내역 기록
      │
      ↓
[Phase 6] 세컨더리 인덱스 업데이트 (체인지 버퍼 or 직접 수정)
      │
      ↓
[Phase 7] "UPDATE 완료" 응답
      │
      ↓
클라이언트: COMMIT
      │
      ↓
[Phase 8] 리두 로그 fsync → "COMMIT 성공" 응답
      │
      ↓ (사용자는 떠남)
      │
[Phase 9] 백그라운드: Double Write → 데이터 파일 쓰기
```

---

## 💡 COMMIT과 fsync의 관계

### 질문: 트랜잭션에서 UPDATE 1000개 + COMMIT 1번이면 fsync는 몇 번?

**답: fsync는 COMMIT 시점에 1번만 발생한다.**

```
[UPDATE 1번째]  → 리두 로그 버퍼에 기록 (메모리)
[UPDATE 2번째]  → 리두 로그 버퍼에 기록 (메모리)
...
[UPDATE 1000번째] → 리두 로그 버퍼에 기록 (메모리)

[COMMIT] → 리두 로그 버퍼에 쌓인 것 전부를 write + fsync → 1번!
```

### 예외: 리두 로그 버퍼가 가득 차는 경우

리두 로그 버퍼의 크기는 `innodb_log_buffer_size` (기본값 16MB)로 제한되어 있다.

```
[UPDATE 1~800번째]  → 리두 로그 버퍼 15.5MB 사용 중...
[UPDATE 801번째]    → 버퍼가 거의 가득 참!
                    → InnoDB: "버퍼 넘치기 전에 OS에 write 해두자"
                    → write 발생 (메모리 → OS 캐시) ← fsync는 아님!

[UPDATE 802~1000번째] → 비워진 버퍼에 계속 기록

[COMMIT] → 남은 것들 write + 전체 fsync (1번)
```

| 동작 | 발생 시점 | 횟수 |
|------|---------|------|
| **write** (→ OS 캐시) | 버퍼가 가득 찰 때 + COMMIT 시 | 1~수 회 |
| **fsync** (→ 디스크) | COMMIT 시 | **딱 1번** |

write는 메모리 간 복사라서 빠르다. **진짜 느린 건 fsync**(디스크에 물리적으로 기록)이고, 이것은 COMMIT당 1번이다.

### 성능 시사점

```java
// ❌ 방법 1: 건건이 커밋 → fsync 1000번
for (int i = 0; i < 1000; i++) {
    memberRepository.updateArea(i, "경기");
    // Spring 기본: 메서드 단위 @Transactional → 매번 COMMIT
}

// ✅ 방법 2: 한 트랜잭션에 묶기 → fsync 1번
@Transactional
public void bulkUpdate() {
    for (int i = 0; i < 1000; i++) {
        memberRepository.updateArea(i, "경기");
    }
    // 메서드 끝에서 COMMIT 1번 → fsync 1번
}
```

| 방법 | fsync 횟수 | 대략적 시간 (HDD 기준) |
|------|-----------|---------------------|
| 건건이 커밋 | 1,000번 | 1,000 × 0.1ms = **100ms** |
| 한 트랜잭션 | 1번 | 0.1ms = **0.1ms** |

**fsync 횟수 차이만으로 1000배 성능 차이**가 날 수 있다.

---

## ❓ 학습 질문

### 질문: 트랜잭션을 크게 묶으면 무조건 좋은가?

> **Q**: 트랜잭션을 크게 묶으면 fsync는 줄어들지만, 그 동안 언두 로그가 계속 쌓이고, X-Lock도 계속 유지된다. 100만 건을 업데이트해야 한다면, 한 트랜잭션에 다 넣을 것인가, 아니면 어떻게 나눌 것인가?
